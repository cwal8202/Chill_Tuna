import pandas as pd
import time
import traceback
from selenium import webdriver
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# --- ì„¤ì • ---
options = Options()
options.add_argument("--start-maximized")
driver = webdriver.Chrome(options=options)
start_url = "https://www.dongwonmall.com/category/main.do?cate_id=01110065" # ìµœìƒìœ„ ì¹´í…Œê³ ë¦¬
driver.get(start_url)
time.sleep(2)

# =======================================================================================
# 1. ë„¤ë¹„ê²Œì´ì…˜ ì •ë³´ ì „ì²´ ìˆ˜ì§‘
# =======================================================================================
print("=========== 1. ì „ì²´ ì¹´í…Œê³ ë¦¬ ë„¤ë¹„ê²Œì´ì…˜ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘ ===========")
all_navigation_tasks = []

# 1-1. 1ì°¨ ì¹´í…Œê³ ë¦¬ ì •ë³´ ìˆ˜ì§‘
l1_elements = driver.find_elements(By.CSS_SELECTOR, "div#allCateList > div.tree-group > ul.list-depth > li.list-item > a")
l1_category_info = []
for elem in l1_elements:
    try:
        name = elem.find_element(By.CSS_SELECTOR, "span.txt").get_attribute("textContent").strip()
        link = elem.get_attribute("href")
        print(f"  â””â”€ [1ì°¨] '{name}' '{link}' ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ.")
        if name and link:
            l1_category_info.append({"name": name, "link": link})
    except NoSuchElementException:
        continue

print(f"ğŸ“Œ ì´ {len(l1_category_info)}ê°œì˜ 1ì°¨ ì¹´í…Œê³ ë¦¬ ë°œê²¬")

# 1-2. ê° ì¹´í…Œê³ ë¦¬ë¥¼ ìˆœíšŒí•˜ë©° ìµœì¢… 3ì°¨ ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ì¶œ
for l1_cat in l1_category_info:
    l1_name = l1_cat['name']
    l1_link = l1_cat['link']
    
    try:
        print(f"\n[1ì°¨] '{l1_name}' íƒìƒ‰ ì¤‘...")
        driver.get(l1_link)
        time.sleep(1)

        # 1-3. 2ì°¨ ì¹´í…Œê³ ë¦¬ ì •ë³´ ìˆ˜ì§‘
        l2_elements = driver.find_elements(By.CSS_SELECTOR, "div#nowCateList > div.tree-group > ul.list-depth > li.list-item >  ul.list-depth > li.list-item > a")
        if not l2_elements:
            print(f"  â””â”€ 2ì°¨ ì¹´í…Œê³ ë¦¬ ì—†ìŒ.")
            continue
        
        l2_category_info = []
        for elem in l2_elements:
            name = elem.get_attribute("textContent").strip()
            onclick = elem.get_attribute("href")
            if name and "changeCategory" in onclick:
                l2_category_info.append({"name": name, "onclick": onclick})

        # 1-4. 3ì°¨ ì¹´í…Œê³ ë¦¬ ì •ë³´ ìˆ˜ì§‘
        for l2_cat in l2_category_info:
            l2_name = l2_cat['name']
            l2_onclick = l2_cat['onclick']
            print(f"  â””â”€ [2ì°¨] '{l2_name}' íƒìƒ‰ ì¤‘...")
            
            driver.execute_script(l2_onclick)
            time.sleep(1)

            l3_elements = driver.find_elements(By.CSS_SELECTOR, "div#nowCateList ul.list-depth.morethan > li > ul.list-depth.morethan > li > a")
            if not l3_elements:
                print(f"    â””â”€ 3ì°¨ ì¹´í…Œê³ ë¦¬ ì—†ìŒ.")
                continue

            for elem in l3_elements:
                l3_name = elem.get_attribute("textContent").strip()
                l3_onclick = elem.get_attribute("href")
                if l3_name and "changeCategory" in l3_onclick:
                    print(f"      â””â”€ [3ì°¨] '{l3_name}' ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ.")
                    # ìµœì¢… ì‘ì—… ëª©ë¡ì— ì¶”ê°€
                    all_navigation_tasks.append({
                        "l1_name": l1_name, "l1_link": l1_link,
                        "l2_name": l2_name, "l2_onclick": l2_onclick,
                        "l3_name": l3_name, "l3_onclick": l3_onclick
                    })
    except Exception as e:
        print(f"ğŸš¨ '{l1_name}' ì¹´í…Œê³ ë¦¬ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
        traceback.print_exc()
        continue

print(f"\n=========== âœ… ì´ {len(all_navigation_tasks)}ê°œì˜ ìµœì¢… ì¹´í…Œê³ ë¦¬ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ===========")


# =======================================================================================
# 2. ìˆ˜ì§‘ëœ ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° í¬ë¡¤ë§
# =======================================================================================
print("\n=========== 2. ì‹¤ì œ ë°ì´í„° í¬ë¡¤ë§ ì‹œì‘ ===========")
all_data = []

for i, task in enumerate(all_navigation_tasks):
    print(f"\nğŸ” [{i+1}/{len(all_navigation_tasks)}] ì‘ì—… ì‹œì‘: {task['l1_name']} > {task['l2_name']} > {task['l3_name']}")
    
    try:
        # ê° ì‘ì—…ë§ˆë‹¤ ì•ˆì •ì„±ì„ ìœ„í•´ 1ì°¨ ì¹´í…Œê³ ë¦¬ë¶€í„° ë‹¤ì‹œ ì‹œì‘
        driver.get(task['l1_link'])
        time.sleep(1)
        driver.execute_script(task['l2_onclick'])
        time.sleep(1)
        driver.execute_script(task['l3_onclick'])
        time.sleep(2)

        # "ë¦¬ë·° ë§ì€ìˆœ" í´ë¦­
        try:
            sort_buttons = WebDriverWait(driver, 5).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "span.sort")))
            review_sort_btn = next((btn for btn in sort_buttons if btn.text.strip() == "ë¦¬ë·° ë§ì€ìˆœ"), None)
            if review_sort_btn:
                review_sort_btn.click()
                time.sleep(2)
        except TimeoutException:
            print("  â””â”€ âš ï¸ ì •ë ¬ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ê·¸ëŒ€ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")

        # í˜ì´ì§€ ìˆœíšŒí•˜ë©° ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ (ìµœëŒ€ 10í˜ì´ì§€)
        max_pages = 10
        for page_num in range(1, max_pages + 1):
            print(f"  â””â”€ í˜ì´ì§€ {page_num}/{max_pages}")
            try:
                WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "ul#bandBestList > li.product_item")))
            except TimeoutException:
                print("    â””â”€ âš ï¸ ìƒí’ˆ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                break

            items = driver.find_elements(By.CSS_SELECTOR, "ul#bandBestList > li.product_item")
            if not items:
                print("    â””â”€ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
                break

            for item in items:
                try:
                    name = item.find_element(By.CSS_SELECTOR, "p.name").text.strip()
                    price = item.find_element(By.CSS_SELECTOR, "div.price_info span.new_price strong").text.strip()
                    grade = item.find_element(By.CSS_SELECTOR, "span.star_rating span.grade").text.strip()
                    review = item.find_element(By.CSS_SELECTOR, "span.star_rating span.review").text.strip()
                    all_data.append({
                        "1ì°¨ ì¹´í…Œê³ ë¦¬": task['l1_name'], "2ì°¨ ì¹´í…Œê³ ë¦¬": task['l2_name'], "3ì°¨ ì¹´í…Œê³ ë¦¬": task['l3_name'],
                        "í˜ì´ì§€": page_num, "ìƒí’ˆëª…": name, "ê°€ê²©": price, "í‰ì ": grade, "ë¦¬ë·° ìˆ˜": review
                    })
                except NoSuchElementException:
                    continue # ì¼ë¶€ ì •ë³´ ì—†ëŠ” ìƒí’ˆì€ ê±´ë„ˆë›°ê¸°
            
            if page_num < max_pages:
                try:
                    next_page_link = driver.find_element(By.XPATH, f"//div[contains(@class, 'paging')]//a[text()='{page_num + 1}']")
                    driver.execute_script("arguments[0].click();", next_page_link)
                    time.sleep(2)
                except NoSuchElementException:
                    print("    â””â”€ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì´ ì—†ì–´ ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break
    except Exception as e:
        print(f"ğŸš¨ğŸš¨ğŸš¨ ì‘ì—… [{i+1}] ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ. ì´ ì‘ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        traceback.print_exc()
        continue


# --- ì €ì¥ ---
driver.quit()
if all_data:
    df = pd.DataFrame(all_data)
    file_name = f"dongwonmall_final_reviews.xlsx"
    df.to_excel(file_name, index=False)
    print(f"\nâœ… ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(df)}ê°œ ìƒí’ˆ ì €ì¥ë¨ â†’ {file_name}")
else:
    print("\nâŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")